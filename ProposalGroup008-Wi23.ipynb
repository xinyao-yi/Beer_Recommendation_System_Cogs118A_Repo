{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64323303",
   "metadata": {},
   "source": [
    "# What kind of Beer do you want?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132393c8",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- George Liu, A15836054\n",
    "- Xinyao Yi, A59019592\n",
    "- Yingnan Yang, A16018172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fe929",
   "metadata": {},
   "source": [
    "### TODO List:\n",
    "- randomized grid search\n",
    "- l1/l2 regularization term/penalty for feature selection\n",
    "\n",
    "Make sure to focus on model selection\n",
    "explain choice of activation functions, models, train test validation split, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6643c6",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "For adults, beer is one of the most highly consumed beverages; wouldn't you want to find a beer that is best for you? In order to do this, we want to examine how people rate beers. This includes things such as alcohol percentage, smell, and taste. Our goal is to build a model that predicts the ratings of beer given these attributes/features, extend the model to also recommend beers based upon your own preferences to these features.\n",
    "\n",
    "Once we filter our dataset with the necessary features, we will train a baseline linear regression model and then a more complex fully connected neural network to see how it performs, using metrics such as RMSE, MAE, and R2 correlation coefficient. These metrics will help us determine the best model, and in turn allow us to recommend the best beer for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b25b3",
   "metadata": {},
   "source": [
    "# Background\n",
    "Our research problem is pretty unique in that researches don’t look into a topic like this. Mostly, this is because this topic is not super important to globalization and technological improvements. There are some works that are similar in topic, but none are academic. \n",
    "\n",
    "One way people use this dataset is to research the types of preferences people have in beer, things like how much foam a person wants, how much alcohol percentage is in the drink, etc. This mostly is used for improving the sales of beer and crafting the best drink. <sup>[1](#preferences)</sup>\n",
    "\n",
    "Others have used beer reviews as a way for classification, being easily able to classify a beer into some categories for ease and also increases sales. <sup>[2](#classification)</sup>\n",
    "\n",
    "A similar drink to beer is wine, and they are experimenting with computer vision to find when the optimal time is to use the ingredients, aka harvesting the grapes. A similar application can be used on barley, the ingredient to make beer. <sup>[3](#beer)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c0ee7",
   "metadata": {},
   "source": [
    "# Problem Statement/Research Problem\n",
    "We aim to suggest the best beer for you based upon common beer preferences; things such as alcohol level, appearence, bitterness, etc. In the process of doing this, we will also aim to predict ratings on a scale 1-5, based upon these preferences; which can be replicated through our model architecture (there is no randomness). This problem is both quantifiable (as our predicted ratings we can get a definite number), and also measurable, through our error metrics that we present below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab7345",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/rdoume/beerreviews\n",
    "This dataset can be found above at the link provided. It around 1.5 million beer reviews, and 13 total features. Each sample will consist of something similar to the name of the drink, a few columns representing the preferences of beers like alcohol level, and then the overall review rating. For our data, we need preprocess by filtering out useless columns and also selecting columns that can easily fit into our neural network architecture (for example getting columns that are integers/floats). Additionally, we will also have to one hot encode features that are important but categorical variables, for instance beer style. We also should drop any sample that is empty in the columns that we find useful.\n",
    "\n",
    "To create our training set and test set, we need to first extract the overall rating score from the dataset as our y values (labels). Then, we extract all the columns that we find important and use that as our X. Then we can use test_train split to get the necessary proportions for our model to be generalizable. We can also split into a validation set, because we have so much data.\n",
    "\n",
    "Below, you will be able to see how we pre processed our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44eb03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 21:59:12.214090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 21:59:12.452781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 21:59:12.452825: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 21:59:14.895653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 21:59:14.895779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 21:59:14.895792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1feedef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643e6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5a1b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_profilename</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1234817823</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>stcules</td>\n",
       "      <td>Hefeweizen</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Sausa Weizen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1235915097</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>stcules</td>\n",
       "      <td>English Strong Ale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Red Moon</td>\n",
       "      <td>6.2</td>\n",
       "      <td>48213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1235916604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>stcules</td>\n",
       "      <td>Foreign / Export Stout</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Black Horse Black Beer</td>\n",
       "      <td>6.5</td>\n",
       "      <td>48215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1234725145</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>stcules</td>\n",
       "      <td>German Pilsener</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sausa Pils</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075</td>\n",
       "      <td>Caldera Brewing Company</td>\n",
       "      <td>1293735206</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>johnmichaelsen</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Cauldron DIPA</td>\n",
       "      <td>7.7</td>\n",
       "      <td>64883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brewery_id             brewery_name  review_time  review_overall  \\\n",
       "0       10325          Vecchio Birraio   1234817823             1.5   \n",
       "1       10325          Vecchio Birraio   1235915097             3.0   \n",
       "2       10325          Vecchio Birraio   1235916604             3.0   \n",
       "3       10325          Vecchio Birraio   1234725145             3.0   \n",
       "4        1075  Caldera Brewing Company   1293735206             4.0   \n",
       "\n",
       "   review_aroma  review_appearance review_profilename  \\\n",
       "0           2.0                2.5            stcules   \n",
       "1           2.5                3.0            stcules   \n",
       "2           2.5                3.0            stcules   \n",
       "3           3.0                3.5            stcules   \n",
       "4           4.5                4.0     johnmichaelsen   \n",
       "\n",
       "                       beer_style  review_palate  review_taste  \\\n",
       "0                      Hefeweizen            1.5           1.5   \n",
       "1              English Strong Ale            3.0           3.0   \n",
       "2          Foreign / Export Stout            3.0           3.0   \n",
       "3                 German Pilsener            2.5           3.0   \n",
       "4  American Double / Imperial IPA            4.0           4.5   \n",
       "\n",
       "                beer_name  beer_abv  beer_beerid  \n",
       "0            Sausa Weizen       5.0        47986  \n",
       "1                Red Moon       6.2        48213  \n",
       "2  Black Horse Black Beer       6.5        48215  \n",
       "3              Sausa Pils       5.0        47969  \n",
       "4           Cauldron DIPA       7.7        64883  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880592e",
   "metadata": {},
   "source": [
    "Creating a beer dictionary to pull up the names later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb22eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_dict = dict(zip(df['beer_name'], df['beer_beerid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c45d93",
   "metadata": {},
   "source": [
    "Getting the true review score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23cdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:, 'review_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b06afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['brewery_id','brewery_name','review_time','review_profilename', 'beer_name','review_overall'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b44bc9",
   "metadata": {},
   "source": [
    "Need to one hot encode beer style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5279a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df['beer_style'])\n",
    "df = pd.concat([df, one_hot], axis=1)\n",
    "X = df.drop('beer_style', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59326402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "      <th>Altbier</th>\n",
       "      <th>American Adjunct Lager</th>\n",
       "      <th>American Amber / Red Ale</th>\n",
       "      <th>American Amber / Red Lager</th>\n",
       "      <th>...</th>\n",
       "      <th>Scotch Ale / Wee Heavy</th>\n",
       "      <th>Scottish Ale</th>\n",
       "      <th>Scottish Gruit / Ancient Herbed Ale</th>\n",
       "      <th>Smoked Beer</th>\n",
       "      <th>Tripel</th>\n",
       "      <th>Vienna Lager</th>\n",
       "      <th>Weizenbock</th>\n",
       "      <th>Wheatwine</th>\n",
       "      <th>Winter Warmer</th>\n",
       "      <th>Witbier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>48213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>48215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>64883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_aroma  review_appearance  review_palate  review_taste  beer_abv  \\\n",
       "0           2.0                2.5            1.5           1.5       5.0   \n",
       "1           2.5                3.0            3.0           3.0       6.2   \n",
       "2           2.5                3.0            3.0           3.0       6.5   \n",
       "3           3.0                3.5            2.5           3.0       5.0   \n",
       "4           4.5                4.0            4.0           4.5       7.7   \n",
       "\n",
       "   beer_beerid  Altbier  American Adjunct Lager  American Amber / Red Ale  \\\n",
       "0        47986        0                       0                         0   \n",
       "1        48213        0                       0                         0   \n",
       "2        48215        0                       0                         0   \n",
       "3        47969        0                       0                         0   \n",
       "4        64883        0                       0                         0   \n",
       "\n",
       "   American Amber / Red Lager  ...  Scotch Ale / Wee Heavy  Scottish Ale  \\\n",
       "0                           0  ...                       0             0   \n",
       "1                           0  ...                       0             0   \n",
       "2                           0  ...                       0             0   \n",
       "3                           0  ...                       0             0   \n",
       "4                           0  ...                       0             0   \n",
       "\n",
       "   Scottish Gruit / Ancient Herbed Ale  Smoked Beer  Tripel  Vienna Lager  \\\n",
       "0                                    0            0       0             0   \n",
       "1                                    0            0       0             0   \n",
       "2                                    0            0       0             0   \n",
       "3                                    0            0       0             0   \n",
       "4                                    0            0       0             0   \n",
       "\n",
       "   Weizenbock  Wheatwine  Winter Warmer  Witbier  \n",
       "0           0          0              0        0  \n",
       "1           0          0              0        0  \n",
       "2           0          0              0        0  \n",
       "3           0          0              0        0  \n",
       "4           0          0              0        0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62df54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_aroma         float64\n",
       "review_appearance    float64\n",
       "review_palate        float64\n",
       "review_taste         float64\n",
       "beer_abv             float64\n",
       "                      ...   \n",
       "Vienna Lager           uint8\n",
       "Weizenbock             uint8\n",
       "Wheatwine              uint8\n",
       "Winter Warmer          uint8\n",
       "Witbier                uint8\n",
       "Length: 110, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cd1b0",
   "metadata": {},
   "source": [
    "Note: We have a huge number of columns/features because of one hot encoding, which is why we selected to use decision trees as our baseline model, since they are not affected by the number of features while linear regression is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3397d5d",
   "metadata": {},
   "source": [
    "Splitting data into train, test, and validation. We can do this because we have so much data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad66235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6261928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert everything to float for ease of use\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099f9df",
   "metadata": {},
   "source": [
    "# Proposed Solution:\n",
    "We will first create a baseline decision tree model to get a feel for how it performs. We don't expect this to be great, because it will train slow compared to a neural network and is prone to overfitting since we haven't done any particular model selection on it. However, it will help determine the relationship between features and help select which features are the most important to help other models. \n",
    "\n",
    "From these results, we will create a fully connected neural network, which is useful because it can use backpropogation to fix previous misclassifications. This will make the model much more accurate. \n",
    "\n",
    "Finally, using the neural network, we will create a basic recommendation system that takes input from the user and inputs into our model to predict. We will need to add some logic to return the name of the beer that the model prediction corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f58dd",
   "metadata": {},
   "source": [
    "# Evaluation Metrics:\n",
    "\n",
    "Our model isn't doing any classification, we already know all drinks that we predict are going to be beers. That means things like confusion matricies, F1 score, precision, etc. are not applicable. Instead, we would have to use things like Mean Absolute Error, Root Mean Squared Error, and R2 correlation coefficients to evaluate our models. \n",
    "\n",
    "MAE is less sensitive to outliers than other metrics and is interpretable while RMSE penalizes the large errors. We will take both of these factors into account when choosing the best model and analyzing our results. Further, we can also use R2 correlation coefficient to help assess how good our predicted model is on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486647b",
   "metadata": {},
   "source": [
    "# Preliminary Results:\n",
    "\n",
    "Here, we will train our baseline decision tree and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477410ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38ce7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ffaf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5721208b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('review_taste', 0.985284179045517)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "feature_importances = sorted(zip(X.columns, feature_importances))\n",
    "max(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f4f34",
   "metadata": {},
   "source": [
    "We can see in our model, the most important feature is the taste. However, it is taking way too much percentage, the other columns should have some weight. This is something to consider when we implement our further models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab1746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f1c13dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.2398467 , 3.6422907 , 3.6422907 , 4.02011732, 4.02011732])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea615bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 4.5, 5. , 4. , 4.5], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b3bab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6820952104504717"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b36b911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9143309128078987"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0311129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6231856243974903"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f88515",
   "metadata": {},
   "source": [
    "Our baseline model obviously doesn't perform great, so we want to hypertune the parameters using random gridsearch. We choose to use random because it increases speed of training (since we are doing this on datahub). Also, it helps prevent overfitting.\n",
    "\n",
    "\n",
    "TODO: not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b5a1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e306e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dist = {\"max_depth\": [3, 5, 7, 10, None],\n",
    "#               \"min_samples_split\": randint(2, 20),\n",
    "#               \"min_samples_leaf\": randint(1, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d74bbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61e29c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1386ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a68eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc4e43",
   "metadata": {},
   "source": [
    "# Ethics/Privacy:\n",
    "\n",
    "There is definitely bias when in this dataset. We say this because as humans, we don't really rate things 0 or 5 on a 0-5 scale. Unless something is super bad or super good, we probably would rate it in between something like 3.5 to 4.5. This can severely affect our model predictions, but doesn't really have a good solution for it. \n",
    "\n",
    "Additionally, the ratings of some samples may occur when a person is already drunk, causing them to rate much higher or lower than if they were sober. It may also depend on how much fun they had while drunk. This also is sampling error, which we can't do much about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7a9fd",
   "metadata": {},
   "source": [
    "# Team Expectations\n",
    "\n",
    "* Be available on the weekends to work together if neccessary, otherwise individually complete assigned work during weekday\n",
    "* Inform all team members through group chat on updates/something is pushed to github\n",
    "* Finish all required parts at least 2 days before deadline is due"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5d3f4",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/16  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/17  |  10 AM |  Do background research on topic and come up with basic model (George) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/20  | 10 PM  | Edit, finalize, and submit proposal; Search for datasets (All)  | Assign group members to lead each specific part   |\n",
    "| 3/1  | 6 PM  | Begin Neural Network architecture design/programming(George) | Discuss Analysis Plan   |\n",
    "| 3/4 | 12 PM  | Write recommendation system(George) | Discuss/edit project code; Complete project |\n",
    "| 3/12  | 12 PM  | Draft results/conclusion/discussion (Xinyao/Yingnan)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee593084",
   "metadata": {},
   "source": [
    "# Footnotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f47e3",
   "metadata": {},
   "source": [
    "<a name=\"preferences\">1</a>: AI of Things, one Telefonica Tech´s business unit. “The Use of AI and Machine Learning in the Beer Industry.” Think Big/Business, 18 June 2021, https://business.blogthinkbig.com/the-use-of-ai-and-machine-learning-in-the-beer-industry/. <br>\n",
    "\n",
    "<a name=\"classification\">2</a>: da Costa, Nattane Luíza, et al. “A Review on the Application of Chemometrics and Machine Learning Algorithms to Evaluate Beer Authentication - Food Analytical Methods.” SpringerLink, Springer US, 26 Sept. 2020, https://link.springer.com/article/10.1007/s12161-020-01864-7. \n",
    "\n",
    "\n",
    "<a name=\"beer\">3</a>: Editor, MathWorks. “Making Better Beer and Wine with Data and Machine Learning.” Medium, MathWorks, 23 Sept. 2020, https://medium.com/mathworks/making-better-beer-and-wine-with-data-and-machine-learning-dd04459f53b7. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
